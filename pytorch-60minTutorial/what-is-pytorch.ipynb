{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit ('torchEnv': pyenv)",
   "display_name": "Python 3.8.5 64-bit ('torchEnv': pyenv)",
   "metadata": {
    "interpreter": {
     "hash": "2c92d966cd6d614aca0ee7d626700fdc5945b0d74bba3d9cf69f3cd79513d971"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Pytorch\n",
    "python 기반의 과학 연산 패키지로 다음과 같은 두 집단을 대상으로 합니다.\n",
    "* Numpy를 대체하면서 GPU를 이용한 연산이 필요한 경우.\n",
    "* 최대한 유연성과 속도를 제공하는 딥러닝 연구 플랫폼이 필요한 경우."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Tensors\n",
    "Numpy의 ndarray와 유사하며, GPU를 사용한 연산 가속이 가능합니다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch"
   ]
  },
  {
   "source": [
    "초기화되지 않은 5x3 행렬을 생성합니다.\n",
    "\n",
    "> 초기화되지 않은 행렬이 선언되었지만, 사용하기 전에는 명확히 알려진 값을 포함하고 있지는 않습니다. 초기화되지 않은 행렬이 생성되면 그 시점에 할당된 메모리에 존재하던 값들이 초기값으로 나타납니다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[-3.4229e-19,  4.5839e-41,  4.8794e-11],\n        [ 3.0854e-41,  1.3556e-19,  1.8567e-01],\n        [ 7.5553e+28,  5.2839e-11,  2.9396e+29],\n        [ 1.2681e-14,  2.0319e-43,  0.0000e+00],\n        [-3.4228e-19,  4.5839e-41, -3.4228e-19]])\n"
    }
   ],
   "source": [
    "x = torch.empty(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "source": [
    "무작위로 초기화된 행렬을 생성합니다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[0.5963, 0.9885, 0.3998],\n        [0.8336, 0.9068, 0.7597],\n        [0.6472, 0.3066, 0.2029],\n        [0.0023, 0.1466, 0.0020],\n        [0.5550, 0.3138, 0.8907]])\n"
    }
   ],
   "source": [
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "source": [
    "dtype이 long이고 0으로 채워진 행렬을 생성합니다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[0, 0, 0],\n        [0, 0, 0],\n        [0, 0, 0],\n        [0, 0, 0],\n        [0, 0, 0]])\n"
    }
   ],
   "source": [
    "x = torch.zeros(5, 3, dtype=torch.long)\n",
    "print(x)"
   ]
  },
  {
   "source": [
    "데이터로부터 tensor를 직접 생성합니다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([5.5000, 3.0000])\n"
    }
   ],
   "source": [
    "x = torch.tensor([5.5, 3])\n",
    "print(x)"
   ]
  },
  {
   "source": [
    "기존 tensor을 바탕으로 새로운  tensor을 만듭니다. 이들 메소드(method)는 사용자로부터 새로운 값을 제공받지 않은 한, 입력 tensor의 속성들을 재사용합니다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[1., 1., 1.],\n        [1., 1., 1.],\n        [1., 1., 1.],\n        [1., 1., 1.],\n        [1., 1., 1.]], dtype=torch.float64)\n"
    }
   ],
   "source": [
    "x = x.new_ones(5, 3, dtype=torch.double)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[-0.8236,  0.2366,  1.3145],\n        [-0.0413, -0.0112, -0.4685],\n        [ 0.3668, -0.4564,  1.4305],\n        [-1.1291, -0.1744, -0.1620],\n        [ 0.6410,  0.1915, -0.5809]])\n"
    }
   ],
   "source": [
    "x = torch.randn_like(x, dtype=torch.float)\n",
    "print(x)"
   ]
  },
  {
   "source": [
    "행렬의 크기를 구합니다\n",
    "\n",
    "> `torch.size` 는 튜플(tuple) 타입으로, 모든 튜플 연산을 지원합니다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([5, 3])\n"
    }
   ],
   "source": [
    "print(x.size())"
   ]
  },
  {
   "source": [
    "# 연산(Operations)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 덧샘"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[-0.1196,  0.2630,  1.4959],\n        [ 0.0112,  0.3705, -0.2613],\n        [ 0.6006, -0.0819,  1.9354],\n        [-0.5265,  0.1848,  0.0530],\n        [ 1.4501,  0.9217, -0.1907]])\n"
    }
   ],
   "source": [
    "y = torch.rand(5, 3)\n",
    "print(x + y)"
   ]
  },
  {
   "source": [
    "print(torch.add(x, y))"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[-0.1196,  0.2630,  1.4959],\n        [ 0.0112,  0.3705, -0.2613],\n        [ 0.6006, -0.0819,  1.9354],\n        [-0.5265,  0.1848,  0.0530],\n        [ 1.4501,  0.9217, -0.1907]])\n"
    }
   ]
  },
  {
   "source": [
    "결과 Tensor를 인자로 제공"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[-0.1196,  0.2630,  1.4959],\n        [ 0.0112,  0.3705, -0.2613],\n        [ 0.6006, -0.0819,  1.9354],\n        [-0.5265,  0.1848,  0.0530],\n        [ 1.4501,  0.9217, -0.1907]])\n"
    }
   ],
   "source": [
    "result = torch.empty(5, 3)\n",
    "torch.add(x, y, out=result)\n",
    "print(result)"
   ]
  },
  {
   "source": [
    "바꿔치기(`in-place`) 방식\n",
    "\n",
    "> 바꿔치기(`in-place`) 방식으로 tensor의 값을 변경하는 연산 뒤에는 `_` 가 붇습니다.\n",
    "\n",
    "> 예시: `x.copy(y)`, `x.t_()` 는 `x` 를 변경합니다. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[-0.9432,  0.4996,  2.8104],\n        [-0.0301,  0.3593, -0.7298],\n        [ 0.9674, -0.5383,  3.3659],\n        [-1.6555,  0.0104, -0.1089],\n        [ 2.0911,  1.1132, -0.7716]])\n"
    }
   ],
   "source": [
    "y.add_(x)\n",
    "print(y)"
   ]
  },
  {
   "source": [
    "Numpy의 인덱싱 표기 방법을 사용할 수 있습니다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([ 0.2366, -0.0112, -0.4564, -0.1744,  0.1915])\n"
    }
   ],
   "source": [
    "print(x[:, 1])"
   ]
  },
  {
   "source": [
    "## 크기 변경\n",
    "\n",
    "tensor의 크기(size)나 모양(shape)을 변경하고 싶다면 `torch.view`를 사용합니다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
    }
   ],
   "source": [
    "x = torch.randn(4, 4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1, 8)\n",
    "\n",
    "print(x.size(), y.size(), z.size())"
   ]
  },
  {
   "source": [
    "만약 tensor에 하나의 값만 존재한다면 `.item()` 을 사용하면 숫자 값을 얻을 수 있습니다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([-0.5203])\n-0.5202743411064148\n"
    }
   ],
   "source": [
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())"
   ]
  },
  {
   "source": [
    "# Numpy 변환\n",
    "\n",
    "(Torch Tensor가 CPU 상에 있다면) Torch Tensor와 Numpy 배열은 메모리 공간을 공유하기 때문에, 하나를 변경하면 다른 하나도 변경됩니다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Torch Tensor를 Numpy 배열로 변환하기"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([1., 1., 1., 1., 1.])\n"
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[1. 1. 1. 1. 1.]\n"
    }
   ],
   "source": [
    "b = a.numpy()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([2., 2., 2., 2., 2.])\n[2. 2. 2. 2. 2.]\n"
    }
   ],
   "source": [
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "source": [
    "## Numpy 배열을 Torch Tensor로 변환하기"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[2. 2. 2. 2. 2.]\ntensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
    }
   ],
   "source": [
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a, 1, out=a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "source": [
    "CharTensor를 제외한 CPU 상의 모든 Tensor는 Numpy로 변환할 수 있고, 반대 변환도 가능합니다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Cuda Tensor\n",
    "\n",
    "`.to` 메소드를 사용하여 Tensor를 어떤 장치로도 욺길 수 있습니다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([0.4797], device='cuda:0')\ntensor([0.4797], dtype=torch.float64)\n"
    }
   ],
   "source": [
    "# 이 코드는 CUDA가 사용가능한 환경에서만 실행됩니다.\n",
    "# torch.device를 사용하여 tensor를 GPU에서 CPU로 이동합니다.\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    y = torch.ones_like(x, device=device)\n",
    "    x = x.to(device)\n",
    "    z = x + y\n",
    "\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))"
   ]
  }
 ]
}