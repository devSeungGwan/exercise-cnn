{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit ('torchEnv': pyenv)",
   "display_name": "Python 3.8.5 64-bit ('torchEnv': pyenv)",
   "metadata": {
    "interpreter": {
     "hash": "2c92d966cd6d614aca0ee7d626700fdc5945b0d74bba3d9cf69f3cd79513d971"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# AUTOGRAD: ìë™ ë¯¸ë¶„\n",
    "\n",
    "pytorchì˜ ëª¨ë“  ì‹ ê²½ë§ ì¤‘ì‹¬ì—ëŠ” `AUTOGRAD` íŒ¨í‚¤ì§€ê°€ ìˆìŠµë‹ˆë‹¤. 'AUTOGRAD' íŒ¨í‚¤ì§€ëŠ” Tensorì˜ ëª¨ë“  ì—°ì‚°ì— ëŒ€í•´ ìë™ ë¯¸ë¶„ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
    "ì´ëŠ” ì‹¤í–‰-ê¸°ë°˜ ì •ì˜(`define-by-run`) í”„ë ˆì„ì›Œí¬ë¡œ, ì´ëŠ” ì½”ë“œë¥¼ ì–´ë–»ê²Œ ì‘ì„±í•˜ì—¬ ì‹¤í–‰í•˜ëŠëƒì— ë”°ë¼ ì—­ì „íŒŒê°€ ì •ì˜ëœë‹¤ëŠ” ëœ»ì´ë©°, ì—­ì „íŒŒëŠ” í•™ìŠµ ê³¼ì •ì˜ ë§¤ ë‹¨ê³„ë§ˆë‹¤ ë‹¬ë¼ì§‘ë‹ˆë‹¤."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Tensor\n",
    "\n",
    "íŒ¨í‚¤ì§€ì˜ ì¤‘ì‹¬ì—ëŠ” `torch.Tensor` í´ë˜ìŠ¤ê°€ ìˆìŠµë‹ˆë‹¤. ë§Œì•½ `.requires_grad` ì†ì„±ì„ `True`ë¡œ ì„¤ì •í•˜ë©´, í•´ë‹¹ Tensorì—ì„œ ì´ë¤„ì§„ ëª¨ë“  ì—°ì‚°ë“¤ì„ ì¶”ì (Track)í•˜ê¸° ì‹œì‘í•©ë‹ˆë‹¤.\n",
    "ê³„ì‚°ì´ ì™„ë£Œëœ í›„, `.backward()`ë¥¼ í˜¸ì¶œí•˜ì—¬ ëª¨ë“  ë³€í™”ë„(gradient)ë¥¼ ìë™ìœ¼ë¡œ ê³„ì‚°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. í•´ë‹¹ Tensorì˜ ë³€í™”ë„ëŠ” `.grad` ì†ì„±ì— ëˆ„ì ë©ë‹ˆë‹¤.\n",
    "\n",
    "Tensorê°€ ê¸°ë¡ ì¶”ì í•˜ëŠ” ê²ƒì„ ì¤‘ë‹¨í•˜ê²Œ í•˜ë ¤ë©´, `.detach()` ë¥¼ í˜¸ì¶œí•˜ì—¬ ì—°ì‚° ê¸°ë¡ìœ¼ë¡œë¶€í„° ë¶„ë¦¬(detach)í•©ë‹ˆë‹¤.\n",
    "\n",
    "ê¸°ë¡ì„ ì¶”ì í•˜ëŠ” ê²ƒ(ê³¼ ë©”ëª¨ë¦¬ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒ)ì„ ë°©ì§€í•˜ê¸° ìœ„í•´, ì½”ë“œ ë¸”ëŸ­ì„ `with torch.no_grad():` ë¡œ ê°ìŒ€ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "ì´ëŠ” íŠ¹íˆ ë³€í™”ë„(gradient)ëŠ” í•„ìš”ì—†ì§€ë§Œ, requires_grad=True ê°€ ì„¤ì •ë˜ì–´ í•™ìŠµ ê°€ëŠ¥í•œ ë§¤ê°œë³€ìˆ˜ë¥¼ ê°–ëŠ” ëª¨ë¸ì„ í‰ê°€(Evaluate)í•  ë•Œ ìœ ìš©í•©ë‹ˆë‹¤.\n",
    "\n",
    "Autogard êµ¬í˜„ì—ì„œ ë§¤ìš° ì¤‘ìš”í•œ í´ë˜ìŠ¤ê°€ í•˜ë‚˜ ë” ìˆëŠ”ë°, `Function` í´ë˜ìŠ¤ì…ë‹ˆë‹¤.\n",
    "\n",
    "`Tensor`ì™€ `Function`ì€ ì„œë¡œ ì—°ê²°ë˜ì–´ ìˆìœ¼ë©°, ëª¨ë“  ì—°ì‚° ê³¼ì •ì„ ë¶€í˜¸í™”(Encode)í•˜ì—¬ ìˆœí™˜í•˜ì§€ ì•Šì€ ê·¸ë˜í”„(acyclic graph)ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "ê° tensorëŠ” `.grad_fn` ì†ì„±ì„ ê°–ê³  ìˆëŠ”ë°, ì´ëŠ” `Tensor`ë¥¼ ìƒì„±í•œ `Function`ì„ ì°¸ì¡°í•˜ê³  ìˆìŠµë‹ˆë‹¤. (ë‹¨, ì‚¬ìš©ìê°€ ë§Œë“  TensorëŠ” ì˜ˆì™¸ë¡œ, `grad_fn=None`)\n",
    "\n",
    "ë„í•¨ìˆ˜ë¥¼ ê³„ì‚°í•˜ê¸° ìœ„í•´ì„œëŠ” `Tensor`ì˜ `.backward()`ë¥¼ í˜¸ì¶œí•˜ë©´ ë©ë‹ˆë‹¤. ë§Œì•½ `Tensor`ê°€ ìŠ¤ì¹¼ë¼(scalar)ì¸ ê²½ìš°(ex. í•˜ë‚˜ì˜ ìš”ì†Œ ê°’ë§Œ ê°–ëŠ” ê²½ìš°)ì—ëŠ” `backward`ì— ì¸ìë¥¼ ì •í•´ì¤„ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ì—¬ëŸ¬ ê°œì˜ ìš”ì†Œë¥¼ ê°–ê³  ìˆì„ ë•ŒëŠ” tensorì˜ ëª¨ì–‘ì„ `gradient`ì˜ ì¸ìë¡œ ì§€ì •í•  í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "import torch"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 16,
   "outputs": []
  },
  {
   "source": [
    "tensorë¥¼ ìƒì„±í•˜ê³  `requires_grad=True`ë¥¼ ì„¤ì •í•˜ì—¬ ì—°ì‚°ì„ ê¸°ë¡í•©ë‹ˆë‹¤."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[1., 1.],\n        [1., 1.]], requires_grad=True)\n"
    }
   ],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "source": [
    "Tensorì— ì—°ì‚°ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[3., 3.],\n        [3., 3.]], grad_fn=<AddBackward0>)\n"
    }
   ],
   "source": [
    "y = x + 2\n",
    "print(y)"
   ]
  },
  {
   "source": [
    "`y`ëŠ” ì—°ì‚°ì˜ ê²°ê³¼ë¡œ ìƒì„±ëœ ê²ƒì´ë¯€ë¡œ `grad_fn`ì„ ê°–ìŠµë‹ˆë‹¤."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<AddBackward0 object at 0x7fdede461790>\n"
    }
   ],
   "source": [
    "print(y.grad_fn)"
   ]
  },
  {
   "source": [
    "`y`ì— ë‹¤ë¥¸ ì—°ì‚°ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[27., 27.],\n        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward0>)\n"
    }
   ],
   "source": [
    "z = y * y * 3\n",
    "out = z.mean()\n",
    "\n",
    "print(z, out)"
   ]
  },
  {
   "source": [
    "`.requires_grad_(...)` ëŠ” ê¸°ì¡´ Tensorì˜ `requires_grad` ê°’ì„ ë°”ê¿”ì¹˜ê¸°(in-place)í•˜ì—¬ ë³€ê²½í•©ë‹ˆë‹¤. ì…ë ¥ê°’ì´ ì§€ì •ë˜ì§€ ì•Šìœ¼ë©´ ê¸°ë³¸ê°’ì€ `False` ì…ë‹ˆë‹¤."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "False\n"
    }
   ],
   "source": [
    "a = torch.randn(2, 2)\n",
    "a = ((a * 3) / (a - 1))\n",
    "print(a.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[65.0804, -2.2994],\n        [-1.1172,  0.1594]], requires_grad=True)"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "a.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor(4242.0127, grad_fn=<SumBackward0>)\n"
    }
   ],
   "source": [
    "b = (a * a).sum()\n",
    "print(b)"
   ]
  },
  {
   "source": [
    "# ë³€í™”ë„(Gradient)\n",
    "\n",
    "ì—­ì „íŒŒë¥¼ í†µí•´ ë³€í™”ë„ë¥¼ ì „íŒŒí•©ë‹ˆë‹¤. `out`ì€ í•˜ë‚˜ì˜ ìŠ¤ì¹¼ë¼ ê°’ë§Œ ê°–ê³  ìˆê¸° ë–„ë¬¸ì—, `out_.backward()`ëŠ” `out.backward(torch.tensor(1.))` ê³¼ ë™ì¼í•©ë‹ˆë‹¤."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[4.5000, 4.5000],\n        [4.5000, 4.5000]])\n"
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "source": [
    "You should have got a matrix of ``4.5``. Letâ€™s call the ``out``\n",
    "*Tensor* â€œ$o$â€.\n",
    "We have that $o = \\frac{1}{4}\\sum_i z_i$,\n",
    "$z_i = 3(x_i+2)^2$ and $z_i\\bigr\\rvert_{x_i=1} = 27$.\n",
    "Therefore,\n",
    "$\\frac{\\partial o}{\\partial x_i} = \\frac{3}{2}(x_i+2)$, hence\n",
    "$\\frac{\\partial o}{\\partial x_i}\\bigr\\rvert_{x_i=1} = \\frac{9}{2} = 4.5$.\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "ì¼ë°˜ì ìœ¼ë¡œ `torch.autograd`ëŠ” ë²¡í„°-ì•„ì½”ë¹„ì•ˆ ê³±ì„ ê³„ì‚°í•˜ëŠ” ì—”ì§„ì…ë‹ˆë‹¤.\n",
    "\n",
    "ì¦‰, ì–´ë–¤ ë²¡í„° ğ‘£=(ğ‘£1ğ‘£2â‹¯ğ‘£ğ‘š)ğ‘‡ ì— ëŒ€í•´ ğ‘£ğ‘‡â‹…ğ½ ì„ ì—°ì‚°í•©ë‹ˆë‹¤.\n",
    "\n",
    "ë§Œì•½ ğ‘£ ê°€ ìŠ¤ì¹¼ë¼ í•¨ìˆ˜  ğ‘™=ğ‘”(ğ‘¦âƒ— ) ì˜ ê¸°ìš¸ê¸°ì¸ ê²½ìš°, ğ‘£=(âˆ‚ğ‘™âˆ‚ğ‘¦1â‹¯âˆ‚ğ‘™âˆ‚ğ‘¦ğ‘š)ğ‘‡ ì´ë©°, ì—°ì‡„ë²•ì¹™(chain rule)ì— ë‹¤ë¼ ë²¡í„°-ì•„ì½”ë¹„ì•ˆ ê³±ì€  ğ‘¥âƒ— ì— ëŒ€í•œ ğ‘™ ì˜ ê¸°ìš¸ê¸°ê°€ ë©ë‹ˆë‹¤."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "(ì—¬ê¸°ì„œ ğ‘£ğ‘‡â‹…ğ½ ì€ ğ½ğ‘‡â‹…ğ‘£ ë¥¼ ì·¨í–ˆì„ ë•Œì˜ ì—´ ë²¡í„°ë¡œ ì·¨ê¸‰í•  ìˆ˜ ìˆëŠ” í–‰ ë²¡í„°ë¥¼ ê°–ìŠµë‹ˆë‹¤.)\n",
    "\n",
    "ë²¡í„°-ì•¼ì½”ë¹„ì•ˆ ê³±ì˜ ì´ëŸ¬í•œ íŠ¹ì„±ì€ ìŠ¤ì¹¼ë¼ê°€ ì•„ë‹Œ ì¶œë ¥ì„ ê°–ëŠ” ëª¨ë¸ì— ì™¸ë¶€ ë³€í™”ë„ë¥¼ ì œê³µ(feed)í•˜ëŠ” ê²ƒì„ ë§¤ìš° í¸ë¦¬í•˜ê²Œ í•´ì¤ë‹ˆë‹¤."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([ -442.3408, -1297.2008,  -764.4599], grad_fn=<MulBackward0>)\n"
    }
   ],
   "source": [
    "x = torch.randn(3, requires_grad=True)\n",
    "\n",
    "y = x * 2\n",
    "\n",
    "while y.data.norm() < 1000:\n",
    "    y *= 2\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([1.0240e+02, 1.0240e+03, 1.0240e-01])\n"
    }
   ],
   "source": [
    "v = torch.tensor([.1, 1., 1e-4], dtype=torch.float)\n",
    "y.backward(v)\n",
    "\n",
    "print(x.grad)"
   ]
  },
  {
   "source": [
    "ë˜í•œ `with torch.no_grad():`ë¡œ ì½”ë“œ ë¸”ë¡ì„ ê°ì‹¸ì„œ autogradê°€ `.requires_grad=True`ì¸ Tensorë“¤ì˜ ì—°ì‚° ê¸°ë¡ì„ ì¶”ì í•˜ëŠ” ê²ƒì„ ë©ˆì¶œ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "True\nTrue\nFalse\n"
    }
   ],
   "source": [
    "print(x.requires_grad)\n",
    "print((x ** 2).requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    print((x**2).requires_grad)"
   ]
  },
  {
   "source": [
    "ë˜ëŠ” `.detach()` ë¥¼ í˜¸ì¶œí•˜ì—¬ ë‚´ìš©ë¬¼(content)ì€ ê°™ì§€ë§Œ, `require_grad`ê°€ ë‹¤ë¥¸ ìƒˆë¡œìš´ Tensorë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "True\nFalse\ntensor(True)\n"
    }
   ],
   "source": [
    "print(x.requires_grad)\n",
    "y = x.detach()\n",
    "print(y.requires_grad)\n",
    "print(x.eq(y).all())"
   ]
  }
 ]
}